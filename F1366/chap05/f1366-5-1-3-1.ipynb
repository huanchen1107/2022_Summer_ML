{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install hyperas","metadata":{"execution":{"iopub.status.busy":"2021-06-04T04:22:49.943142Z","iopub.execute_input":"2021-06-04T04:22:49.943502Z","iopub.status.idle":"2021-06-04T04:22:57.640221Z","shell.execute_reply.started":"2021-06-04T04:22:49.943428Z","shell.execute_reply":"2021-06-04T04:22:57.639326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from hyperopt import hp\nfrom hyperopt import Trials, tpe\nfrom hyperas import optim\nfrom hyperas.distributions import choice, uniform\n\ndef prepare_data():\n    \"\"\" \n    準備資料\n    \"\"\"\n    # 欲使用的函式庫\n    import numpy as np\n    import pandas as pd\n    from sklearn.model_selection import KFold\n    ## keras modules\n    from tensorflow.keras.utils import to_categorical\n    from tensorflow.keras.models import Sequential\n    from tensorflow.keras.layers import Dense, Dropout, Flatten # core layers\n    from tensorflow.keras.layers import Conv2D, MaxPooling2D # convolution layers\n\n    # 從train.csv讀入pandas的DataFrame\n    train = pd.read_csv('/kaggle/input/digit-recognizer/train.csv') \n    train_x = train.drop(['label'], axis=1)   # 從train取出圖像資料 \n    train_y = train['label']                  # 從train取出正確答案\n    test_x = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\n     # 將train的資料分為訓練資料與驗證資料。\n    kf = KFold(n_splits=4, shuffle=True, random_state=123)\n    tr_idx, va_idx = list(kf.split(train_x))[0]\n    tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n    tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n\n    # 將圖像的像素值除以255.0，限制在0 ~ 1.0的範圍內，並轉換為numpy.array\n    tr_x, va_x = np.array(tr_x / 255.0), np.array(va_x / 255.0)\n\n    # 將二維矩陣的圖像數據變換成(高度 = 28, 寬度 = 28, 通道 = 1)的三維矩陣。\n    # 灰階圖片的通道數為1。\n    tr_x = tr_x.reshape(-1,28,28,1)\n    va_x = va_x.reshape(-1,28,28,1)\n\n    # 將正確答案轉換為One-hot encoding呈現\n    tr_y = to_categorical(tr_y, 10)\n    va_y = to_categorical(va_y, 10)\n    return tr_x, tr_y, va_x, va_y  \n\ndef create_model(tr_x, tr_y): \n    \"\"\" \n    建立模型\n    \"\"\" \n    # 建立Sequential物件 \n    model = Sequential()  \n    # 探索第1層的過濾器數量、過濾器尺寸\n    model.add(Conv2D(filters={{choice([32, 64])}},\n                     kernel_size={{choice([(3,3), (5,5), (7,7)])}},\n                     padding='same',\n                     activation={{choice(['tanh', 'relu'])}},\n                     input_shape=(28,28,1)))\n\n    # 探索第2層的過濾器數量、過濾器尺寸\n    model.add(Conv2D(filters = {{choice([32, 64])}},\n                     kernel_size = {{choice([(3,3), (5,5), (7,7)])}},\n                     padding='same',\n                     activation={{choice(['tanh', 'relu'])}}))\n\n    # 在第3層配置2×2的池化層\n    model.add(MaxPooling2D(pool_size=(2,2)))\n\n    # 探索丟棄率。\n    model.add(Dropout({{quniform(0.2, 0.6, 0.05)}}))\n\n    # 探索第4層的過濾器數量、過濾器尺寸\n    model.add(Conv2D(filters={{choice([32, 64])}},\n                     kernel_size={{choice([(3,3), (5,5), (7,7)])}},\n                     padding='same',\n                     activation='relu'))\n\n    # 探索第5層的過濾器數量、過濾器尺寸\n    model.add(Conv2D(filters = {{choice([32, 64])}},\n                     kernel_size = {{choice([(3,3), (5,5), (7,7)])}},\n                     padding='same',\n                     activation={{choice(['tanh', 'relu'])}} )) \n    \n    # 在第6層配置2×2的池化層 \n    model.add(MaxPooling2D(pool_size=(2,2)))  \n    \n    # 探索丟棄率\n    model.add(Dropout({{quniform(0.2, 0.6, 0.05)}}))\n\n    # 配置扁平層\n    model.add(Flatten())\n\n    # 從1,2裡面探索要追加的層的數量\n    if {{choice(['one', 'two'])}} == 'one':\n        \"\"\" \n        選到one的時候就配置第7層，並探索神經元數量、激活函數、丟棄率\n        \"\"\"\n        # 第7層\n        model.add(Dense({{choice([500, 600, 700])}},\n                        activation={{choice(['tanh', 'relu'])}}))\n        model.add(Dropout({{quniform(0.1, 0.6, 0.05)}}))\n        \n    elif {{choice(['one', 'two'])}} == 'two':\n        \"\"\"\n        選到two的時候就配置第7層跟第8層，並探索神經元數量、激活函數、丟棄率\n        \"\"\"\n\n        # 第7層\n        model.add(Dense({{choice([500, 600, 700])}},\n                        activation={{choice(['tanh', 'relu'])}}))\n        model.add(Dropout({{quniform(0.1, 0.6, 0.05)}}))\n        \n        # 第8層\n        model.add(Dense({{choice([100, 150, 200])}},\n                        activation={{choice(['tanh', 'relu'])}}))\n        model.add(Dropout({{quniform(0.2, 0.6, 0.05)}}))\n    \n    # 放置輸出層\n    model.add(Dense(10, activation = \"softmax\"))\n\n    # 模型編譯\n    # 嘗試使用Adam跟RMSprop作為優化器\n    model.compile(loss=\"categorical_crossentropy\",\n                  optimizer={{choice(['adam', 'rmsprop'])}},\n                  metrics=[\"accuracy\"])\n\n    # 訓練次數為30次\n    epoch = 30\n\n    # 用100與200作為批次大小。\n    batch_size = {{choice([100, 200, 300])}}\n    result = model.fit(tr_x, tr_y,\n                       epochs=epoch,\n                       batch_size=batch_size,\n                       validation_data=(va_x, va_y),\n                       verbose=0)\n\n    # 簡單輸出訓練時的結果\n    validation_acc = np.amax(result.history['val_accuracy'])\n    print('Best validation acc of epoch:', validation_acc)\n\n    # 探索如何能讓validation_acc數值最小化\n    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n\n# 設定執行75次的探索\nbest_run, best_model = optim.minimize(model=create_model,\n                                      data=prepare_data,\n                                      algo=tpe.suggest,\n                                      max_evals=75,\n                                      eval_space=True,\n                                      notebook_name='__notebook_source__',\n                                      trials=Trials())\n","metadata":{"execution":{"iopub.status.busy":"2021-06-04T04:22:57.642044Z","iopub.execute_input":"2021-06-04T04:22:57.642388Z","iopub.status.idle":"2021-06-04T04:30:10.021366Z","shell.execute_reply.started":"2021-06-04T04:22:57.642351Z","shell.execute_reply":"2021-06-04T04:30:10.020539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 輸出準確度最高的模型\nprint(best_model.summary()) \n# 輸出準確度最好的參數數值\nprint(best_run)\n\n# 使用驗證資料檢驗已完成探索的模型。\n_, _, va_x, va_y = prepare_data()\nval_loss, val_acc = best_model.evaluate(va_x, va_y)\nprint(\"val_loss: \", val_loss)    # 輸出損失\nprint(\"val_acc: \", val_acc)      # 輸出準確度\n","metadata":{"execution":{"iopub.status.busy":"2021-06-04T04:30:10.024438Z","iopub.execute_input":"2021-06-04T04:30:10.024689Z","iopub.status.idle":"2021-06-04T04:30:17.566739Z","shell.execute_reply.started":"2021-06-04T04:30:10.024663Z","shell.execute_reply":"2021-06-04T04:30:17.565953Z"},"trusted":true},"execution_count":null,"outputs":[]}]}