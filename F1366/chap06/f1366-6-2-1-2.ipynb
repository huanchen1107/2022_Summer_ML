{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.utils import to_categorical\n\ndef prepare_data():\n    \"\"\" \n    準備資料\n    Returns:\n        X_train(ndarray): 訓練資料 (50000.32.32.3)\n        X_test(ndarray): 測試資料 (10000.32.32.3)\n        y_train(ndarray): 將訓練資料的正確答案用One-hot encoding後表示 (50000,10)\n        y_train(ndarray): 將測試資料的正確答案用One-hot encoding後表示 (10000,10)\n        y_test_label(ndarray): 測試資料的正確答案 (10000)\n    \"\"\"\n    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n    # 對訓練資料與測試資料的圖像執行正規化\n    x_train, x_test = x_train.astype('float32'), x_test.astype('float32')\n    x_train, x_test = x_train/255.0, x_test/255.0\n    # 將訓練資料與測試資料的的正確答案用One-hot encoding後表示\n    y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n\n    return x_train, x_test, y_train, y_test\n","metadata":{"execution":{"iopub.status.busy":"2021-07-05T06:09:41.384459Z","iopub.execute_input":"2021-07-05T06:09:41.385099Z","iopub.status.idle":"2021-07-05T06:09:47.444735Z","shell.execute_reply.started":"2021-07-05T06:09:41.38499Z","shell.execute_reply":"2021-07-05T06:09:47.443707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras import optimizers\n\ndef make_convlayer():\n    \"\"\" \n    建立模型\n    \"\"\"\n    # Sequential物件\n    model = Sequential()\n    # 卷積層 1\n    model.add(Conv2D(filters=64, \n                     kernel_size=3, \n                     padding='same',\n                     activation='relu', \n                     input_shape=(32,32,3)))\n    # 2 × 2 池化層\n    model.add(MaxPooling2D(pool_size=2))\n    # 卷積層 2\n    model.add(Conv2D(filters=128, \n                     kernel_size=3, \n                     padding='same',\n                     activation='relu'))\n    # 2 × 2 池化層\n    model.add(MaxPooling2D(pool_size=2))\n    # 卷積層 3\n    model.add(Conv2D(filters=256, \n                     kernel_size=3, \n                     padding='same',\n                     activation='relu')) \n    #2 × 2 池化層 \n    model.add(MaxPooling2D(pool_size=2)) \n    # 扁平層 \n    model.add(Flatten()) \n    # 丟棄法\n    model.add(Dropout(0.4))\n    # 第7層\n    model.add(Dense(512, activation='relu'))\n    # 輸出層\n    model.add(Dense(10, activation='softmax'))\n\n    # 優化器為 Adam\n    model.compile(loss=\"categorical_crossentropy\",\n                  optimizer=optimizers.Adam(lr=0.001),\n                  metrics=[\"accuracy\"])\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2021-07-05T06:09:47.446139Z","iopub.execute_input":"2021-07-05T06:09:47.446418Z","iopub.status.idle":"2021-07-05T06:09:47.45804Z","shell.execute_reply.started":"2021-07-05T06:09:47.446392Z","shell.execute_reply":"2021-07-05T06:09:47.457064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler, Callback\nfrom tensorflow.keras.callbacks import Callback\n\nclass LRHistory(Callback):\n    def on_train_begin(self, logs={}):\n        self.acc = []\n        self.lr = []\n    def on_epoch_end(self, batch, logs={}):\n        self.acc.append(logs.get('acc'))\n        self.lr.append(step_decay(len(self.acc)))\n\ndef step_decay(epoch): \n    \"\"\"\n    運用步驟衰減讓學習率降低的函數  \n    Returns: 學習率 (float) \n    \"\"\" \n    initial_lrate = 0.001   # 初始學習率 \n    drop = 0.5              # 衰減率 \n    epochs_drop = 10.0      # 每10個訓練週期後要進行學習率衰減\n    lrate = initial_lrate * math.pow(drop,\n                                     math.floor((epoch)/epochs_drop))\n    return lrate\n\ndef train(x_train, x_test, y_train, y_test):\n\n    model = make_convlayer()\n    lr_history = LRHistory()\n    lrate = LearningRateScheduler(step_decay)\n    callbacks_list = [lr_history, lrate]\n\n    # 資料擴增\n    datagen = ImageDataGenerator(width_shift_range=0.1,  # 以圖像寬度的0.1比例隨機橫向移動\n                                 height_shift_range=0.1, # 以圖像高度的0.1比例隨機上下移動\n                                 rotation_range=10,      # 在10度的範圍內隨機旋轉\n                                 zoom_range=0.1,         # 以原始尺寸的0.1比例隨機放大\n                                 horizontal_flip=True)   # 左右翻轉\n\n    # 批次大小\n    batch_size = 128\n    # 訓練週期\n    epochs = 100\n\n    # 訓練\n    history = model.fit(datagen.flow(x_train, # 看批次大小多少，就建立多少的擴增資料\n                                     y_train,\n                                     batch_size=batch_size),\n                        steps_per_epoch=x_train.shape[0] // batch_size,# 每次訓練當中的步驟次數\n                        epochs=epochs,                                 # 訓練週期 \n                        verbose=1,                                     # 輸出訓練進度的情況\n                        validation_data=(x_test, y_test),              # 驗證資料\n                        callbacks=callbacks_list\n                       )\n\n    return history, lr_history\n","metadata":{"execution":{"iopub.status.busy":"2021-07-05T06:09:47.4601Z","iopub.execute_input":"2021-07-05T06:09:47.460462Z","iopub.status.idle":"2021-07-05T06:09:47.474779Z","shell.execute_reply.started":"2021-07-05T06:09:47.460427Z","shell.execute_reply":"2021-07-05T06:09:47.473755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = prepare_data()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T06:09:47.47632Z","iopub.execute_input":"2021-07-05T06:09:47.476692Z","iopub.status.idle":"2021-07-05T06:09:54.209867Z","shell.execute_reply.started":"2021-07-05T06:09:47.476663Z","shell.execute_reply":"2021-07-05T06:09:54.208845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nhistory, lr_history = train(x_train, x_test, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T06:09:54.211451Z","iopub.execute_input":"2021-07-05T06:09:54.21187Z","iopub.status.idle":"2021-07-05T06:42:18.183778Z","shell.execute_reply.started":"2021-07-05T06:09:54.211826Z","shell.execute_reply":"2021-07-05T06:42:18.182525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\nx_range = list(range(1, len(lr_history.lr)+1))\n\n# 設定繪圖尺寸\nplt.figure(figsize=(15, 10))     # 將圖形縮小、讓圖形之間保有空間 \nplt.subplots_adjust(wspace=0.2)  # 在2 × 1 格線的上方繪圖 \nplt.subplot(2, 1, 1)             # 繪製訓練資料與驗證資料的準確度 \nplt.plot(x_range, history.history['accuracy'], label='train', linestyle='--')\nplt.plot(x_range, history.history['val_accuracy'], label='Val Acc')\nplt.legend()                     # 顯示圖例\n\nplt.grid()                       # 顯示格線\nplt.xlabel('Epoch')              # x 軸標籤\nplt.ylabel('Acc')                # y 軸標籤\n\n# 在2 × 1 格線的下方繪圖\nplt.subplot(2, 1, 2)             # 繪製學習率 \nplt.plot(x_range, lr_history.lr, label='Learning Rate')\nplt.legend()                     # 顯示圖例\nplt.grid()                       # 顯示格線\nplt.xlabel('Epoch')              # x 軸標籤\nplt.ylabel('Learning Rate')      # y 軸標籤\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-05T06:42:18.185182Z","iopub.execute_input":"2021-07-05T06:42:18.185487Z","iopub.status.idle":"2021-07-05T06:42:18.22154Z","shell.execute_reply.started":"2021-07-05T06:42:18.185456Z","shell.execute_reply":"2021-07-05T06:42:18.219336Z"},"trusted":true},"execution_count":null,"outputs":[]}]}