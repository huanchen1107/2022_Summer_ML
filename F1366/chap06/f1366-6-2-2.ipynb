{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.utils import to_categorical\n\ndef prepare_data():\n    \"\"\" \n    準備資料\n    Returns:\n        X_train(ndarray): 訓練資料 (50000.32.32.3)\n        X_test(ndarray): 測試資料 (10000.32.32.3)\n        y_train(ndarray): 將訓練資料改為One-hot encoding後的標籤 (50000,10)\n        y_train(ndarray): 將測試資料改為One-hot encoding後的標籤 (10000,10)\n        y_test_label(ndarray): 測試資料的正確答案 (10000)\n    \"\"\"\n    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n    # 對訓練資料與測試資料的圖像執行常規化\n    x_train, x_test = x_train.astype('float32'), x_test.astype('float32')\n    x_train, x_test = x_train/255.0, x_test/255.0\n    # 將訓練資料與測試資料的標籤轉換為以One-hot encoding來呈現10的類別\n    y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n\n    return x_train, x_test, y_train, y_test\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras import optimizers\n\ndef make_convlayer():\n    \"\"\" \n    建立模型\n    \"\"\"\n    # Sequential物件\n    model = Sequential()\n    # 卷積層 1\n    model.add(Conv2D(filters=64, \n                     kernel_size=3, \n                     padding='same',\n                     activation='relu', \n                     input_shape=(32,32,3)))\n    # 2 × 2 池化層\n    model.add(MaxPooling2D(pool_size=2))\n    # 卷積層 2\n    model.add(Conv2D(filters=128, \n                     kernel_size=3, \n                     padding='same',\n                     activation='relu'))\n    # 2 × 2 池化層\n    model.add(MaxPooling2D(pool_size=2))\n    # 卷積層 3\n    model.add(Conv2D(filters=256, \n                     kernel_size=3, \n                     padding='same',\n                     activation='relu')) \n    #2 × 2 池化層 \n    model.add(MaxPooling2D(pool_size=2)) \n    # 扁平層 \n    model.add(Flatten()) \n    # 丟棄法\n    model.add(Dropout(0.4))\n    # 第7層\n    model.add(Dense(512, activation='relu'))\n    # 輸出層\n    model.add(Dense(10, activation='softmax'))\n\n    # 優化器為 Adam\n    model.compile(loss=\"categorical_crossentropy\",\n                  optimizer=optimizers.Adam(lr=0.001),\n                  metrics=[\"accuracy\"])\n    return model\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\ndef train(x_train, x_test, y_train, y_test):\n    \"\"\"\n    Parameters:\n        x_train, x_test, y_train, y_test: 訓練資料與測試資料\n    Returns:\n        History object\n    \"\"\"\n    # 如果經過2個訓練週期仍未看見val_loss獲得改善、就將學習率減為0.5倍。\n    reduce_lr = ReduceLROnPlateau(\n        monitor='val_accuracy',    # 監控對象的驗證資料精確度\n        factor=0.5,                # 衰減學習率的比例\n        patience=5,                # 監控對象的訓練週期次數\n        verbose=1,                 # 降低學習率後執行通知\n        mode='max',                # 監控最高數值 \n        min_lr=0.0001)             # 學習率下限值 \n    \n    model = make_convlayer()\n    callbacks_list = [reduce_lr]\n    \n    # 資料擴增 \n    datagen = ImageDataGenerator(width_shift_range=0.1,   # 以圖像寬度的0.1比例隨機橫向移動 \n                                 height_shift_range=0.1,  # 以圖像高度的0.1比例隨機上下移動\n                                 rotation_range=10,       # 在10度的範圍內隨機旋轉\n                                 zoom_range=0.1,          # 以原始尺寸的0.1比例隨機放大\n                                 horizontal_flip=True)    # 左右翻轉\n\n    # 小批次尺寸\n    batch_size = 128\n    # 訓練次數\n    epochs = 100\n\n    # 訓練\n    history = model.fit(datagen.flow(x_train,# 看小批次的尺寸多少，就生成多少的增補資料\n                                     y_train,\n                                     batch_size=batch_size),\n                        \n                        steps_per_epoch=x_train.shape[0] // batch_size, # 每次訓練的步驟次數\n                        epochs=epochs,                                  # 訓練次數\n                        verbose=1,                                      # 輸出學習進度的情況\n                        validation_data=(x_test, y_test),               # 驗證資料\n                        callbacks=callbacks_list)\n\n    return history\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = prepare_data()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nhistory = train(x_train, x_test, y_train, y_test)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\n# 設定繪圖尺寸\nplt.figure(figsize=(15, 10))\n# 將圖形縮小、讓圖形之間保有空間\nplt.subplots_adjust(wspace=0.2)\n\n# 在2 × 1 格線的上方繪圖\nplt.subplot(2, 1, 1)\n# 繪製訓練資料與驗證資料的準確度\nplt.plot(history.history['accuracy'], label='train', linestyle='--')\nplt.plot(history.history['val_accuracy'], label='Val Acc')\nplt.legend()              # 顯示圖例\nplt.grid()                # 顯示格線\nplt.xlabel('Epoch')       # x 軸標籤\nplt.ylabel('Acc')         # y 軸標籤\n\n# 在2 × 1 格線的下方繪圖\nplt.subplot(2, 1, 2)\n# 繪製學習率\nplt.plot(history.history['lr'], label='Learning Rate')\nplt.legend()                  # 顯示圖例\nplt.grid()                    # 顯示格線\nplt.xlabel('Epoch')           # x 軸標籤\nplt.ylabel('Learning Rate')   # y 軸標籤\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]}]}