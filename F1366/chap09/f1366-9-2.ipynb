{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-06T08:28:34.992073Z","iopub.execute_input":"2021-07-06T08:28:34.992557Z","iopub.status.idle":"2021-07-06T08:28:35.014989Z","shell.execute_reply.started":"2021-07-06T08:28:34.992433Z","shell.execute_reply":"2021-07-06T08:28:35.013475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nimport pandas as pd\ntrain_df = pd.read_table('../input/mercari/train.tsv')\ntest_df = pd.read_table('../input/mercari/test.tsv')\nprint(train_df.shape, test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:28:35.016755Z","iopub.execute_input":"2021-07-06T08:28:35.017404Z","iopub.status.idle":"2021-07-06T08:28:51.64034Z","shell.execute_reply.started":"2021-07-06T08:28:35.017344Z","shell.execute_reply":"2021-07-06T08:28:51.639358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:28:51.642148Z","iopub.execute_input":"2021-07-06T08:28:51.642433Z","iopub.status.idle":"2021-07-06T08:28:51.674364Z","shell.execute_reply.started":"2021-07-06T08:28:51.642405Z","shell.execute_reply":"2021-07-06T08:28:51.673243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:28:51.677854Z","iopub.execute_input":"2021-07-06T08:28:51.678186Z","iopub.status.idle":"2021-07-06T08:28:51.694864Z","shell.execute_reply.started":"2021-07-06T08:28:51.678156Z","shell.execute_reply":"2021-07-06T08:28:51.693699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.drop(train_df[(train_df.price < 3.0)].index)\nprint(train_df.shape)\nprint(train_df['price'].max())\nprint(train_df['price'].min())","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:28:51.696312Z","iopub.execute_input":"2021-07-06T08:28:51.696642Z","iopub.status.idle":"2021-07-06T08:28:51.955075Z","shell.execute_reply.started":"2021-07-06T08:28:51.696611Z","shell.execute_reply":"2021-07-06T08:28:51.953987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ntrain_df['price'].hist()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:28:51.956457Z","iopub.execute_input":"2021-07-06T08:28:51.956758Z","iopub.status.idle":"2021-07-06T08:28:52.226783Z","shell.execute_reply.started":"2021-07-06T08:28:51.956728Z","shell.execute_reply":"2021-07-06T08:28:52.225647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['price'].hist(range=(0, 100))","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:28:52.228278Z","iopub.execute_input":"2021-07-06T08:28:52.228666Z","iopub.status.idle":"2021-07-06T08:28:52.417596Z","shell.execute_reply.started":"2021-07-06T08:28:52.228622Z","shell.execute_reply":"2021-07-06T08:28:52.41683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# 對訓練資料中的price進行對數變換\ntrain_df[\"target\"] = np.log1p(train_df.price)\n# 顯示直方圖\ntrain_df['target'].hist()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:28:52.419374Z","iopub.execute_input":"2021-07-06T08:28:52.419814Z","iopub.status.idle":"2021-07-06T08:28:52.650946Z","shell.execute_reply.started":"2021-07-06T08:28:52.41978Z","shell.execute_reply":"2021-07-06T08:28:52.650106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split_cat(text):\n    \"\"\"\n    將類別以 / 進行切割\n    若無資料時，則傳回 'No Label'\n    \"\"\"\n    try: return text.split('/')\n    except: return ('No Label', 'No Label', 'No Label')\n\n# 將一分為3的類別名稱登錄至'subcat_0'、'subcat_1'、'subcat_2'\ntrain_df['subcat_0'], train_df['subcat_1'], train_df['subcat_2'] = \\\n    zip( * train_df['category_name'].apply(lambda x: split_cat(x)))\n\ntest_df['subcat_0'], test_df['subcat_1'], test_df['subcat_2'] = \\\n    zip( * test_df['category_name'].apply(lambda x: split_cat(x)))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:28:52.652192Z","iopub.execute_input":"2021-07-06T08:28:52.652707Z","iopub.status.idle":"2021-07-06T08:29:05.7883Z","shell.execute_reply.started":"2021-07-06T08:28:52.652672Z","shell.execute_reply":"2021-07-06T08:29:05.787505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:29:05.789894Z","iopub.execute_input":"2021-07-06T08:29:05.790351Z","iopub.status.idle":"2021-07-06T08:29:05.810251Z","shell.execute_reply.started":"2021-07-06T08:29:05.790284Z","shell.execute_reply":"2021-07-06T08:29:05.809214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:29:05.811842Z","iopub.execute_input":"2021-07-06T08:29:05.812302Z","iopub.status.idle":"2021-07-06T08:29:05.835498Z","shell.execute_reply.started":"2021-07-06T08:29:05.812249Z","shell.execute_reply":"2021-07-06T08:29:05.834473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 將train_df與test_df結合\nfull_set = pd.concat([train_df, test_df])\n# 從全部資料中找出所有出現的品牌名稱\nall_brands = set(full_set['brand_name'].values)\n\n# 將'brand_name'的缺失值 NaN置換為'missing'\ntrain_df['brand_name'].fillna(value='missing', inplace=True)\ntest_df['brand_name'].fillna(value='missing', inplace=True)\n\n# 取得訓練資料中缺失值的個數\ntrain_premissing = len(train_df.loc[train_df['brand_name'] \n                                    == 'missing'])\n# 取得測試資料中缺失值的個數\ntest_premissing = len(test_df.loc[test_df['brand_name'] \n                                  == 'missing'])\n\ndef brandfinder(line):\n    \n    \"\"\"\n    Parameters: line(str): 品牌名稱\n    · 將品牌名稱的'missing'替換為商品名稱：\n        當'missing'的商品名稱單詞存在於品牌清單中時\n    · 將品牌名稱替換為商品名稱:\n        當商品名稱與品牌清單中的名稱完全一致時\n    · 維持現有品牌名稱:\n        商品名稱與品牌清單的名稱不一致品牌名稱雖為'missing'，但商品名稱的單詞不在品牌清單內\n    \"\"\"\n    \n    brand = line[0] # 第 1 欄為品牌名稱\n    name = line[1]  # 第 2 欄為商品名稱\n    namesplit = name.split(' ') # 使用空格分割商品名稱\n\n    if brand == 'missing':  # 是缺失值\n        for x in namesplit: # 取出從商品名稱分割出來的單詞\n            if x in all_brands:\n                return name # 商品名稱單詞存在於品牌清單中，則傳回商品名稱單詞\n    if name in all_brands:  # 不是缺失值\n        return name         # 商品名稱若存在於品牌清單中，則傳回商品名稱\n\n    return brand # 都沒有一致的話就傳回品牌名稱\n\n# 更換品牌名稱\ntrain_df['brand_name'] = train_df[['brand_name',\n                                   'name']].apply(brandfinder, \n                                                  axis = 1)\ntest_df['brand_name'] = test_df[['brand_name',\n                                 'name']].apply(brandfinder, \n                                                axis = 1)\n\n# 取得改寫後的缺失值數量\ntrain_len = len(train_df.loc[train_df['brand_name'] == 'missing'])\ntest_len = len(test_df.loc[test_df['brand_name'] == 'missing'])\ntrain_found = train_premissing - train_len\ntest_found = test_premissing - test_len\nprint(train_premissing) # 改寫前訓練資料的缺失值數量\nprint(train_found)      # 改寫後訓練資料的缺失值數量\nprint(test_premissing)  # 改寫前測試資料的缺失值數量\nprint(test_found)       # 改寫後測試資料的缺失值數量\n","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:29:05.83688Z","iopub.execute_input":"2021-07-06T08:29:05.837188Z","iopub.status.idle":"2021-07-06T08:29:40.646004Z","shell.execute_reply.started":"2021-07-06T08:29:05.837158Z","shell.execute_reply":"2021-07-06T08:29:40.64471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:37:57.088926Z","iopub.execute_input":"2021-07-06T08:37:57.089355Z","iopub.status.idle":"2021-07-06T08:37:57.110171Z","shell.execute_reply.started":"2021-07-06T08:37:57.089316Z","shell.execute_reply":"2021-07-06T08:37:57.1091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_df = pd.concat([train_df, test_df], sort=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:37:59.423696Z","iopub.execute_input":"2021-07-06T08:37:59.424087Z","iopub.status.idle":"2021-07-06T08:38:00.586664Z","shell.execute_reply.started":"2021-07-06T08:37:59.424054Z","shell.execute_reply":"2021-07-06T08:38:00.584278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fill_missing_values(df):\n    # 商品類別\n    df.category_name.fillna(value='missing', inplace=True)\n    # 品牌名稱\n    df.brand_name.fillna(value='missing', inplace=True)\n    # 商品敘述\n    df.item_description.fillna(value='missing', inplace=True)\n    # 將敘述中的 'No description yet' 改為 'missing' \n    df.item_description.replace('No description yet',\n                                'missing',\n                                inplace=True)\n    return df\n\nfull_df = fill_missing_values(full_df)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:38:02.250133Z","iopub.execute_input":"2021-07-06T08:38:02.25054Z","iopub.status.idle":"2021-07-06T08:38:03.242091Z","shell.execute_reply.started":"2021-07-06T08:38:02.250494Z","shell.execute_reply":"2021-07-06T08:38:03.241001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nprint(\"Processing categorical data...\")\n\n# 建立LabelEncoder\nle = LabelEncoder()\n# 對'category_name'進行編碼、登錄至'category'欄位\nle.fit(full_df.category_name)\nfull_df['category'] = le.transform(full_df.category_name)\n# 'brand_name'編碼\nle.fit(full_df.brand_name)\nfull_df.brand_name = le.transform(full_df.brand_name)\n# 'subcat_0'編碼\nle.fit(full_df.subcat_0)\nfull_df.subcat_0 = le.transform(full_df.subcat_0)\n# 'subcat_1'編碼\nle.fit(full_df.subcat_1)\nfull_df.subcat_1 = le.transform(full_df.subcat_1)\n# 'subcat_2'編碼\nle.fit(full_df.subcat_2)\nfull_df.subcat_2 = le.transform(full_df.subcat_2)\ndel le","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:38:06.867849Z","iopub.execute_input":"2021-07-06T08:38:06.868406Z","iopub.status.idle":"2021-07-06T08:38:14.406345Z","shell.execute_reply.started":"2021-07-06T08:38:06.868369Z","shell.execute_reply":"2021-07-06T08:38:14.405245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.preprocessing.text import Tokenizer\n\n# 將商品敘述、商品名稱、商品類別如下連接成一為陣列\n# [商品敘述1,商品敘述2, ...,商品名稱1,商品名稱2,...,商品類別,商品類別,...]\n\nprint(\"Transforming text data to sequences...\")\nraw_text = np.hstack([full_df.item_description.str.lower(), # 商品敘述\n                      full_df.name.str.lower(),             # 商品名稱\n                      full_df.category_name.str.lower()])   # 商品類別\nprint('sequences shape', raw_text.shape)\n\n# 建立Tokenizer \nprint(\" Fitting tokenizer...\")\ntok_raw = Tokenizer()\ntok_raw.fit_on_texts(raw_text)\n\n# 使用Tokenizer對商品敘述、商品名稱分別進行標籤編碼\nprint(\" Transforming text to sequences...\")\nfull_df['seq_item_description'] = tok_raw.texts_to_sequences(\n    full_df.item_description.str.lower())\nfull_df['seq_name'] = tok_raw.texts_to_sequences(\n    full_df.name.str.lower())\n\ndel tok_raw\n\nprint(full_df.seq_item_description.head())\nprint(full_df.seq_name.head())\n","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:38:19.006056Z","iopub.execute_input":"2021-07-06T08:38:19.006618Z","iopub.status.idle":"2021-07-06T08:42:15.237796Z","shell.execute_reply.started":"2021-07-06T08:38:19.006582Z","shell.execute_reply":"2021-07-06T08:42:15.236779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\nprint(pad_sequences(full_df.seq_item_description, maxlen=80),'\\n') # 商品敘述\nprint(pad_sequences(full_df.seq_name, maxlen=10))                  # 商品名稱\n","metadata":{"execution":{"iopub.status.busy":"2021-06-22T09:06:26.074385Z","iopub.execute_input":"2021-06-22T09:06:26.074824Z","iopub.status.idle":"2021-06-22T09:07:03.91725Z","shell.execute_reply.started":"2021-06-22T09:06:26.074788Z","shell.execute_reply":"2021-06-22T09:07:03.916118Z"},"trusted":true},"execution_count":null,"outputs":[]}]}