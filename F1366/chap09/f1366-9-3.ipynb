{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%time \nfrom datetime import datetime \nstart_real = datetime.now() # 開始量測整體的處理時間\n\nimport pandas as pd\n# 讀取訓練資料與測試資料\ntrain_df = pd.read_table('../input/mercari/train.tsv')\ntest_df = pd.read_table('../input/mercari/test.tsv')\nprint(train_df.shape, test_df.shape)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-07T06:11:33.249206Z","iopub.execute_input":"2021-07-07T06:11:33.24965Z","iopub.status.idle":"2021-07-07T06:11:48.657632Z","shell.execute_reply.started":"2021-07-07T06:11:33.249561Z","shell.execute_reply":"2021-07-07T06:11:48.655632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.drop(train_df[(train_df.price < 3.0)].index)\ntrain_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-07T06:11:48.659243Z","iopub.execute_input":"2021-07-07T06:11:48.65969Z","iopub.status.idle":"2021-07-07T06:11:48.916321Z","shell.execute_reply.started":"2021-07-07T06:11:48.659646Z","shell.execute_reply":"2021-07-07T06:11:48.915362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n # 確認商品名稱與商品敘述的單詞數量\n\ndef wordCount(text):\n    \"\"\"\n    Parameters:\n        text(str): 商品名稱、商品敘述 \n    \"\"\" \n    try: \n        if text == 'No description yet': \n            return 0 # 商品名稱跟敘述為 'No description yet' 時則傳回0 \n        else: \n            text = text.lower() # 全數改為小寫字母 \n            words = [w for w in text.split(\" \")] # 用空白鍵進行切割 \n            return len(words) # 傳回單詞數量\n    except:\n        return 0\n\n# 將'name'單詞數量紀錄在'name_len'\ntrain_df['name_len'] = train_df['name'].apply(\n    lambda x: wordCount(x))\ntest_df['name_len'] = test_df['name'].apply(\n    lambda x: wordCount(x))\n# 將'item_description'單詞數量紀錄在'desc_len'\ntrain_df['desc_len'] = train_df['item_description'].apply(\n    lambda x: wordCount(x))\ntest_df['desc_len'] = test_df['item_description'].apply(\n    lambda x: wordCount(x))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-07T06:11:48.917791Z","iopub.execute_input":"2021-07-07T06:11:48.918078Z","iopub.status.idle":"2021-07-07T06:12:01.410372Z","shell.execute_reply.started":"2021-07-07T06:11:48.91805Z","shell.execute_reply":"2021-07-07T06:12:01.409198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nimport numpy as np\n\n# 對訓練資料的price進行對數變換\ntrain_df[\"target\"] = np.log1p(train_df.price)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-07T06:12:01.41211Z","iopub.execute_input":"2021-07-07T06:12:01.412764Z","iopub.status.idle":"2021-07-07T06:12:01.454458Z","shell.execute_reply.started":"2021-07-07T06:12:01.41272Z","shell.execute_reply":"2021-07-07T06:12:01.453383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ndef split_cat(text):\n    \"\"\"\n    Parameters:\n    text(str): 類別名稱\n        · 使用 / 分割類別名稱\n        · 若資料不存在 / 時則傳回\"No Label\" \n    \"\"\"\n    try: return text.split(\"/\")\n    except: return (\"No Label\", \"No Label\", \"No Label\")\n\n# 訓練資料\ntrain_df['subcat_0'], train_df['subcat_1'], train_df['subcat_2'] =\\\n    zip( * train_df['category_name'].apply(lambda x: split_cat(x)))\n# 測試資料\ntest_df['subcat_0'], test_df['subcat_1'], test_df['subcat_2'] =\\\n    zip( * test_df['category_name'].apply(lambda x: split_cat(x)))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-07T06:12:01.455786Z","iopub.execute_input":"2021-07-07T06:12:01.456082Z","iopub.status.idle":"2021-07-07T06:12:11.054896Z","shell.execute_reply.started":"2021-07-07T06:12:01.456054Z","shell.execute_reply":"2021-07-07T06:12:11.053723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# 將train_df與test_df結合\nfull_set = pd.concat([train_df, test_df])\n# 從全部資料中找出所有出現的品牌名稱，建立品牌清單\nall_brands = set(full_set['brand_name'].values)\n\n# 將'brand_name'的缺失值 NaN置換為'missing'\ntrain_df['brand_name'].fillna(value='missing', inplace=True)\ntest_df['brand_name'].fillna(value='missing', inplace=True)\n\n# 取得訓練資料中缺失值的個數\ntrain_premissing = len(train_df.loc[train_df['brand_name'] == 'missing'])\n# 取得測試資料中缺失值的個數\ntest_premissing = len(test_df.loc[test_df['brand_name'] == 'missing'])\n\ndef brandfinder(line):\n    \n    \"\"\"\n    Parameters: line(str): 品牌名稱\n    · 將品牌名稱的'missing'替換為商品名稱：\n        當'missing'的商品名稱單詞存在於品牌清單中時\n    · 將品牌名稱替換為商品名稱:\n        當商品名稱與品牌清單中的名稱完全一致時\n    · 維持現有品牌名稱:\n        商品名稱與品牌清單的名稱不一致品牌名稱雖為'missing'，但商品名稱的單詞不在品牌清單內\n    \"\"\"\n    \n    brand = line[0] # 第 1 欄為品牌名稱\n    name = line[1]  # 第 2 欄為商品名稱\n    namesplit = name.split(' ') # 使用空格分割商品名稱\n\n    if brand == 'missing':  # 是缺失值\n        for x in namesplit: # 取出從商品名稱分割出來的單詞\n            if x in all_brands:\n                return name # 商品名稱單詞存在於品牌清單中，則傳回商品名稱單詞\n    if name in all_brands:  # 不是缺失值\n        return name         # 商品名稱若存在於品牌清單中，則傳回商品名稱\n\n    return brand # 都沒有一致的話就傳回品牌名稱\n\n# 更換品牌名稱\ntrain_df['brand_name'] = train_df[['brand_name','name']].apply(\n    brandfinder, axis = 1)\ntest_df['brand_name'] = test_df[['brand_name','name']].apply(\n    brandfinder, axis = 1)\n\n# 取得改寫後的缺失值數量\ntrain_found = train_premissing - len(train_df.loc[train_df['brand_name'] == 'missing'])\ntest_found = test_premissing - len(test_df.loc[test_df['brand_name'] == 'missing'])\nprint(train_premissing) # 改寫前訓練資料的缺失值數量\nprint(train_found)      # 改寫後訓練資料的缺失值數量\nprint(test_premissing)  # 改寫前測試資料的缺失值數量\nprint(test_found)       # 改寫後測試資料的缺失值數量\n","metadata":{"execution":{"iopub.status.busy":"2021-07-07T06:12:11.056196Z","iopub.execute_input":"2021-07-07T06:12:11.056581Z","iopub.status.idle":"2021-07-07T06:12:44.505295Z","shell.execute_reply.started":"2021-07-07T06:12:11.056537Z","shell.execute_reply":"2021-07-07T06:12:44.504246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# 將訓練用的資料框架以99:1的比例分割為訓練資料跟驗證資料\nfrom sklearn.model_selection import train_test_split \nimport gc  \n\ntrain_dfs, dev_dfs = train_test_split(train_df, # 目標資料框架 \n                                      random_state=123, # 亂數生成Seed（種子） \n                                      train_size=0.99, # 用於訓練之99%的資料 \n                                      test_size=0.01) # 用於驗證之1%的資料\n\nn_trains = train_dfs.shape[0] # 訓練資料尺寸\nn_devs = dev_dfs.shape[0]     # 驗證資料尺寸\nn_tests = test_df.shape[0]    # 測試資料尺寸\nprint('Training :', n_trains, 'examples')\nprint('Validating :', n_devs, 'examples')\nprint('Testing :', n_tests, 'examples')\ndel train_df\ngc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-22T09:41:38.886301Z","iopub.execute_input":"2021-06-22T09:41:38.886733Z","iopub.status.idle":"2021-06-22T09:41:41.905402Z","shell.execute_reply.started":"2021-06-22T09:41:38.886674Z","shell.execute_reply":"2021-06-22T09:41:41.904533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# 將訓練資料、驗證資料、測試資料合併\nfull_df = pd.concat([train_dfs, dev_dfs, test_df])\n\ndef fill_missing_values(df):\n    df.category_name.fillna(value='missing', inplace=True)    # 商品類別\n    df.brand_name.fillna(value='missing', inplace=True)       # 品牌名稱\n    df.item_description.fillna(value='missing', inplace=True) # 商品敘述\n    # 將敘述中的 'No description yet' 改為 'missing' \n    df.item_description.replace('No description yet','missing', inplace=True) # 置換商品敘述\n    return df\n\nfull_df = fill_missing_values(full_df)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-22T09:41:41.907301Z","iopub.execute_input":"2021-06-22T09:41:41.907579Z","iopub.status.idle":"2021-06-22T09:41:44.453258Z","shell.execute_reply.started":"2021-06-22T09:41:41.907551Z","shell.execute_reply":"2021-06-22T09:41:44.452203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfrom sklearn.preprocessing import LabelEncoder\n\nprint(\"Processing categorical data...\")\n\n# 建立LabelEncoder\nle = LabelEncoder()\n# 對'category_name'進行編碼、登錄至'category'欄位\nle.fit(full_df.category_name)\nfull_df['category'] = le.transform(full_df.category_name)\n# 'brand_name'編碼\nle.fit(full_df.brand_name)\nfull_df.brand_name = le.transform(full_df.brand_name)\n# 'subcat_0'編碼\nle.fit(full_df.subcat_0)\nfull_df.subcat_0 = le.transform(full_df.subcat_0)\n# 'subcat_1'編碼\nle.fit(full_df.subcat_1)\nfull_df.subcat_1 = le.transform(full_df.subcat_1)\n# 'subcat_2'編碼\nle.fit(full_df.subcat_2)\nfull_df.subcat_2 = le.transform(full_df.subcat_2)\ndel le\ngc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-22T09:41:44.454486Z","iopub.execute_input":"2021-06-22T09:41:44.454775Z","iopub.status.idle":"2021-06-22T09:41:52.347904Z","shell.execute_reply.started":"2021-06-22T09:41:44.454749Z","shell.execute_reply":"2021-06-22T09:41:52.346898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# 對完成連接的商品敘述、商品名稱進行標籤編碼\nfrom tensorflow.keras.preprocessing.text import Tokenizer\n\n\n# 將商品敘述、商品名稱、商品類別如下連接成一為陣列\n# [商品敘述1,商品敘述2, ...,商品名稱1,商品名稱2,...,商品類別,商品類別,...]\n\nprint(\"Transforming text data to sequences...\")\nraw_text = np.hstack([full_df.item_description.str.lower(), # 商品敘述\n                      full_df.name.str.lower(),             # 商品名稱\n                      full_df.category_name.str.lower()])   # 商品類別\nprint('sequences shape', raw_text.shape)\n\nprint(\" Fitting tokenizer...\")\ntok_raw = Tokenizer()\ntok_raw.fit_on_texts(raw_text)\n\nprint(\" Transforming text to sequences...\")\nfull_df['seq_item_description'] = tok_raw.texts_to_sequences(full_df.item_description.str.lower())\nfull_df['seq_name'] = tok_raw.texts_to_sequences(full_df.name.str.lower())\n\ndel tok_raw\ngc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-22T09:41:52.349064Z","iopub.execute_input":"2021-06-22T09:41:52.349338Z","iopub.status.idle":"2021-06-22T09:45:37.176575Z","shell.execute_reply.started":"2021-06-22T09:41:52.349305Z","shell.execute_reply":"2021-06-22T09:45:37.175769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_NAME_SEQ = 10      # 商品名稱的最大尺寸(最大為17，截短為10 )\nMAX_ITEM_DESC_SEQ = 75 # 商品敘述的最大尺寸(最大為269，截短為75 )\nMAX_CATEGORY_SEQ = 8   # 商品類別的最大尺寸(最大為8)\n\n# 商品名稱與商品敘述的單詞數量: 最大值+100\nMAX_TEXT = np.max(\n    [np.max(full_df.seq_name.max()),\n     np.max(full_df.seq_item_description.max())]) + 100\n# 商品類別的單詞數量: 最大值+1\nMAX_CATEGORY = np.max(full_df.category.max()) + 1\n# 品牌名稱的單詞數量: 最大值+1\nMAX_BRAND = np.max(full_df.brand_name.max()) + 1\n# 商品狀態的數量: 最大值+1\nMAX_CONDITION = np.max(full_df.item_condition_id.max()) + 1\n# 商品敘述的單詞數量: 每列單詞數量的最大值+1\nMAX_DESC_LEN = np.max(full_df.desc_len.max()) + 1\n# 商品名稱的單詞數量: 每列單詞數量的最大值+1\nMAX_NAME_LEN = np.max(full_df.name_len.max()) + 1\n# 子類別的單詞數量: 最大值+1\nMAX_SUBCAT_0 = np.max(full_df.subcat_0.max()) + 1\nMAX_SUBCAT_1 = np.max(full_df.subcat_1.max()) + 1\nMAX_SUBCAT_2 = np.max(full_df.subcat_2.max()) + 1\n","metadata":{"execution":{"iopub.status.busy":"2021-06-22T09:47:23.087167Z","iopub.execute_input":"2021-06-22T09:47:23.08751Z","iopub.status.idle":"2021-06-22T09:47:23.929978Z","shell.execute_reply.started":"2021-06-22T09:47:23.087481Z","shell.execute_reply":"2021-06-22T09:47:23.928928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\ndef get_rnn_data(dataset): \n    \"\"\" \n    將輸入的資料放入dict物件後傳回  \n    Parameter: \n        dataset: 全部資料 \n    \"\"\" \n    X = { \n        # 商品名稱 \n        # 墊零以統一序列尺寸: MAX_NAME_SEQ=10\n        'name': pad_sequences(dataset.seq_name,\n                              maxlen=MAX_NAME_SEQ),\n        # 商品敘述\n        # 墊零以統一序列尺寸: MAX_ITEM_DESC_SEQ=75\n        'item_desc': pad_sequences(dataset.seq_item_description,\n                                   maxlen=MAX_ITEM_DESC_SEQ),\n        # 品牌名稱\n        'brand_name': np.array(dataset.brand_name),\n        # 商品類別\n        'category': np.array(dataset.category),\n        # 商品狀態\n        'item_condition': np.array(dataset.item_condition_id),\n        # 運費負擔: 賣方負擔為 1, 買方負擔為0\n        'num_vars': np.array(dataset[[\"shipping\"]]),\n        # 商品敘述\n        'desc_len': np.array(dataset[[\"desc_len\"]]),\n        # 商品名稱\n        'name_len': np.array(dataset[[\"name_len\"]]),\n        # 商品子類別0\n        'subcat_0': np.array(dataset.subcat_0),\n        # 商品子類別1\n        'subcat_1': np.array(dataset.subcat_1),\n        # 商品子類別2\n        'subcat_2': np.array(dataset.subcat_2)}\n    return X\n\n# 訓練資料: 索引0到訓練資料數量的索引為止\ntrain = full_df[:n_trains]\n# 驗證資料: 資料數量的索引到訓練資料數量+驗證資料數量的索引為止\ndev = full_df[n_trains:n_trains+n_devs] \n# 測試資料: 訓練資料+驗證資料的索引開始到最後 \ntest = full_df[n_trains+n_devs:]  \n\n# 取得訓練用的dictionary物件\nX_train = get_rnn_data(train) \n# 將訓練用的商品價格1維陣列轉換為2維矩陣\n# (1466844) ➡ (1466844,1)\nY_train = train.target.values.reshape(-1, 1)\n\n# 取的驗證用的dictionary物件\nX_dev = get_rnn_data(dev)\n# 將驗證用的商品價格1維陣列轉換為2維矩陣\n# (14817) ➡ (14817,1)\nY_dev = dev.target.values.reshape(-1, 1)\n\n# 取的測試用的dictionary\nX_test = get_rnn_data(test)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-22T09:47:26.645991Z","iopub.execute_input":"2021-06-22T09:47:26.646327Z","iopub.status.idle":"2021-06-22T09:48:04.009811Z","shell.execute_reply.started":"2021-06-22T09:47:26.646282Z","shell.execute_reply":"2021-06-22T09:48:04.008839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dropout, Dense, Embedding, Flatten\nfrom tensorflow.keras.layers import concatenate, GRU\nfrom tensorflow.keras.optimizers import Adam\n\nnp.random.seed(123) # 設定亂數種子\n\n# 定義均方根誤差(Root Mean Square Error, RMSE)\n# 用於確認預測狀況\n# 使用此函數時的Y_pred(預測售價)與Y(實際售價)已經有經過對數轉換\n# 因此實質上輸出是對數均方根誤差(Root Mean Squared Logarithmic Error, RMSLE)\ndef rmsle(Y, Y_pred):\n    assert Y.shape == Y_pred.shape\n    return np.sqrt(np.mean(np.square(Y_pred - Y )))\n\ndef new_rnn_model(lr=0.001, decay=0.0):\n    \"\"\"\n    生成循環型類神經網路模型\n    Parameters:\n        lr: 學習率\n        decay: 學習率的衰減\n    \"\"\"\n    # 輸入層\n    # 商品名稱、商品敘述、品牌名稱、商品狀態、負擔運費\n    name           = Input(shape=[X_train[\"name\"].shape[1]],\n                           name=\"name\")\n    item_desc      = Input(shape=[X_train[\"item_desc\"].shape[1]],\n                           name=\"item_desc\")\n    brand_name     = Input(shape=[1], name=\"brand_name\")\n    item_condition = Input(shape=[1], name=\"item_condition\")\n    num_vars       = Input(shape=[X_train[\"num_vars\"].shape[1]],\n                           name=\"num_vars\")\n    # 商品名稱文字、商品敘述文字的單詞數量\n    name_len       = Input(shape=[1], name=\"name_len\")\n    desc_len       = Input(shape=[1], name=\"desc_len\")\n    # 商品子類別\n    subcat_0       = Input(shape=[1], name=\"subcat_0\")\n    subcat_1       = Input(shape=[1], name=\"subcat_1\")\n    subcat_2       = Input(shape=[1], name=\"subcat_2\")\n\n    # Embedding層\n    # 商品名稱Embedding: 輸入為單詞總數 +100、輸出的維數為20\n    emb_name = Embedding(MAX_TEXT, 20)(name)\n    # 商品敘述Embedding: 輸入為單詞總數 +100、輸出的維數為60\n    emb_item_desc = Embedding(MAX_TEXT, 60)(item_desc)\n    # 品牌名稱Embedding: 輸入為單詞總數 +1、輸出的維數為10\n    emb_brand_name = Embedding(MAX_BRAND, 10)(brand_name)\n    # 商品狀態Embedding: 輸入為5+1、輸出的維數為 5\n    emb_item_condition = Embedding(MAX_CONDITION, \n                                   5)(item_condition)\n    # 商品敘述單詞數量Embedding: 輸入為商品敘述的最大單詞數量 +1、輸出為5\n    emb_desc_len = Embedding(MAX_DESC_LEN, 5)(desc_len)\n    # 商品名稱單詞數量Embedding: 輸入為商品名稱的最大單詞數量 +1、輸出為5\n    emb_name_len = Embedding(MAX_NAME_LEN, 5)(name_len)\n    # 商品子類別的Embedding: 輸入為類別名稱的最大單詞數量 +1、輸出為10\n    emb_subcat_0 = Embedding(MAX_SUBCAT_0, 10)(subcat_0)\n    emb_subcat_1 = Embedding(MAX_SUBCAT_1, 10)(subcat_1)\n    emb_subcat_2 = Embedding(MAX_SUBCAT_2, 10)(subcat_2)\n\n    # 門控循環單元\n    rnn_layer1 = GRU(16) (emb_item_desc) # 商品敘述\n    rnn_layer2 = GRU(8) (emb_name)       # 商品名稱\n\n    # 扁平層\n    main_l = concatenate([Flatten()(emb_brand_name), # 品牌名稱 Embedding\n                          Flatten()(emb_item_condition), #商品狀態Embedding\n                          Flatten()(emb_desc_len), # 商品敘述的單詞數量 Embedding\n                          Flatten()(emb_name_len), # 商品名稱的單詞數量 Embedding\n                          Flatten()(emb_subcat_0), # 子類別 0 的 Embedding\n                          Flatten()(emb_subcat_1), # 子類別1 的 Embedding\n                          Flatten()(emb_subcat_2), # 子類別 2 的 Embedding\n                          rnn_layer1, # 商品敘述 GRU Unit\n                          rnn_layer2, # 商品名稱 GRU Unit\n                          num_vars]) #負擔運費(0或1)\n\n    # 全連接層\n    main_l = Dropout(0.1)(Dense(512,\n                                kernel_initializer='normal',\n                                activation='relu')(main_l))\n    main_l = Dropout(0.1)(Dense(256,\n                                kernel_initializer='normal',\n                                activation='relu')(main_l))\n    main_l = Dropout(0.1)(Dense(128,\n                                kernel_initializer='normal',\n                                activation='relu')(main_l))\n    main_l = Dropout(0.1)(Dense(64,\n                                kernel_initializer='normal',\n                                activation='relu')(main_l))\n\n    # 輸出層\n    output = Dense(1,\n                   activation=\"linear\") (main_l)\n\n    # 整合\n    # 因為是多個平行的輸入層，所以將其做成清單\n    model = Model(inputs=[name,\n                          item_desc,\n                          brand_name,\n                          item_condition,\n                          num_vars,\n                          desc_len,\n                          name_len,\n                          subcat_0, \n                          subcat_1, \n                          subcat_2],\n                  # 輸出層\n                  outputs=output)\n\n    # 設定損失函數以及優化器，開始編譯\n    model.compile(loss = 'mse',\n                  optimizer = Adam(lr=lr, decay=decay))\n    \n    return model\n\n# 建立模型\nmodel = new_rnn_model()\nmodel.summary()\n\ndel model\ngc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-22T09:49:54.697915Z","iopub.execute_input":"2021-06-22T09:49:54.698297Z","iopub.status.idle":"2021-06-22T09:49:56.81999Z","shell.execute_reply.started":"2021-06-22T09:49:54.698262Z","shell.execute_reply":"2021-06-22T09:49:56.818981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# 批次大小\nBATCH_SIZE = 512 * 2\nepochs = 3\n\n# 學習率衰減\nexp_decay = lambda init, fin, steps: (init/fin) ** (1/(steps-1)) - 1\nsteps = int(len(X_train['name']) / BATCH_SIZE) * epochs\nlr_init = 0.005\nlr_fin = 0.001\nlr_decay = exp_decay(lr_init, lr_fin, steps)\n\n# 建立模型\nrnn_model = new_rnn_model(lr=lr_init, decay=lr_decay)\n# 訓練模型\nrnn_model.fit(X_train, \n              Y_train,\n              epochs=epochs,\n              batch_size=BATCH_SIZE,\n              validation_data=(X_dev, Y_dev),\n              verbose=1)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-17T10:44:11.059797Z","iopub.execute_input":"2021-06-17T10:44:11.060116Z","iopub.status.idle":"2021-06-17T11:13:52.647194Z","shell.execute_reply.started":"2021-06-17T10:44:11.060072Z","shell.execute_reply":"2021-06-17T11:13:52.645981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# 使用驗證資料評估模型\nprint(\"Evaluating the model on validation data...\")\n# 用訓練完成的模型預測驗證資料進行\nY_dev_preds_rnn = rnn_model.predict(X_dev,\n                                    batch_size=BATCH_SIZE)\n# 使用rmsle()求出均方根誤差\nprint(\"RMSLE error:\", rmsle(Y_dev,            # 驗證資料的商品價格\n                            Y_dev_preds_rnn)) # 預測值","metadata":{"execution":{"iopub.status.busy":"2021-06-17T11:13:52.650811Z","iopub.execute_input":"2021-06-17T11:13:52.651161Z","iopub.status.idle":"2021-06-17T11:13:54.188958Z","shell.execute_reply.started":"2021-06-17T11:13:52.651124Z","shell.execute_reply":"2021-06-17T11:13:54.187899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rnn_preds = rnn_model.predict(X_test, \n                              batch_size=BATCH_SIZE, \n                              verbose=1)\n# 對預測出的商品價格套用指數函數\nrnn_preds = np.expm1(rnn_preds)\ndel rnn_model\ngc.collect()\n\nstop_real = datetime.now()\nexecution_time_real = stop_real-start_real\nprint(execution_time_real)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T11:13:54.190472Z","iopub.execute_input":"2021-06-17T11:13:54.190815Z","iopub.status.idle":"2021-06-17T11:14:31.88127Z","shell.execute_reply.started":"2021-06-17T11:13:54.190781Z","shell.execute_reply":"2021-06-17T11:14:31.880186Z"},"trusted":true},"execution_count":null,"outputs":[]}]}