{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport os, zipfile\nfrom sklearn.model_selection import train_test_split\n\ndef prepareData():\n    \"\"\" \n    讀入資料，並區分訓練資料與驗證資料\n    Returns:\n        train_df(DataFrame)   :從train取出用於訓練的資料 (90%)\n        validate_df(DataFrame):從train取出用於驗證的資料 (10%)\n    \"\"\"\n    # 將訓練資料跟測試資料解壓縮\n    # 解壓縮的zip檔名\n    data = ['train', 'test']\n\n    # 在當前的目錄解壓縮train.zip、test.zip\n    path = '../input/dogs-vs-cats-redux-kernels-edition/'\n    for el in data:\n        with zipfile.ZipFile(path + el + \".zip\", \"r\") as z:\n            z.extractall(\".\")\n\n    # 使用檔名dog.x.jpg、cat.x.jpg，建立標籤1與0 \n    # 取得train資料夾內的檔名，放入filenames\n    filenames = os.listdir(\"./train\")\n    # 放置標籤的清單\n    categories = [] \n    for filename in filenames: \n        # 分割檔名、取出最前頭的元素(dog/cat)\n        # 將dog為1、cat為0設為標籤，放入category  \n        category = filename.split('.')[0] \n        if category == 'dog': # 若為 dog，則加上標籤1  \n            categories.append(1) \n        else: # 若為cat，則加上標籤0\n            categories.append(0)\n\n    # 對df的列filename放入檔名filename\n    # 對列category放入標籤數值categories\n    df = pd.DataFrame({'filename': filenames,\n                       'category': categories})\n\n    # 將訓練資料總數25000已隨機方式分割為90%跟10%、\n    # 90%為用於訓練的資料、10%為用於驗證的資料\n    train_df, validate_df = train_test_split(df, test_size=0.1)\n    # 重新配置列的索引\n    train_df = train_df.reset_index()\n    validate_df = validate_df.reset_index()\n\n    return train_df, validate_df\n","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:52:29.556458Z","iopub.execute_input":"2021-06-22T06:52:29.556898Z","iopub.status.idle":"2021-06-22T06:52:30.547113Z","shell.execute_reply.started":"2021-06-22T06:52:29.556799Z","shell.execute_reply":"2021-06-22T06:52:30.546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ndef ImageDataGenerate(train_df, validate_df):\n    \"\"\"\n    對圖像進行加工\n    parameters:\n        train_df(DataFrame)   : 從train取出用於訓練的資料(90%) \n        validate_df(DataFrame): 從train取出用於驗證的資料(10%) \n    Returns: \n        train_generator(DirectoryIterator)     : 加工過後的訓練資料 \n        validation_generator(DirectoryIterator): 加工過後的驗證資料 \n    \"\"\" \n    # 重新調整圖像尺寸\n    img_width, img_height = 224, 224\n    target_size = (img_width, img_height)\n    # 批次大小\n    batch_size = 16\n\n    # 檔名的欄位名稱，標籤的欄位名稱\n    x_col, y_col = 'filename', 'category'\n    # 設定flow_from_dataframe()的class_mode數值 \n    # 此範例為二元分類，設定值為'binary'\n    class_mode = 'binary'\n\n    # 建立Generator來加工圖像\n    train_datagen = ImageDataGenerator(rotation_range=15,\n                                       rescale=1./255,\n                                       shear_range=0.2,\n                                       zoom_range=0.2,\n                                       horizontal_flip=True,\n                                       fill_mode='nearest',\n                                       width_shift_range=0.1,\n                                       height_shift_range=0.1)\n\n    # 因爲沒有輸出層，故class_mode為None\n    train_generator = train_datagen.flow_from_dataframe(train_df,\n                                                        \"./train/\", \n                                                        x_col=x_col,\n                                                        y_col=y_col,\n                                                        class_mode=None, \n                                                        target_size=target_size,\n                                                        batch_size=batch_size,\n                                                        shuffle=False)\n\n    # 使用Generator產生加工完的驗證資料\n    valid_datagen = ImageDataGenerator(rescale=1./255)\n\n    # 使用Generator產生預處理的驗證資料\n    valid_generator = valid_datagen.flow_from_dataframe(validate_df,\n                                                        \"./train/\", \n                                                        x_col=x_col, \n                                                        y_col=y_col,\n                                                        class_mode=None,\n                                                        target_size=target_size,\n                                                        batch_size=batch_size,\n                                                        shuffle=False)\n\n    # 傳回訓練資料與驗證資料\n    return train_generator, valid_generator \n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:52:30.548574Z","iopub.execute_input":"2021-06-22T06:52:30.548902Z","iopub.status.idle":"2021-06-22T06:52:36.802204Z","shell.execute_reply.started":"2021-06-22T06:52:30.548869Z","shell.execute_reply":"2021-06-22T06:52:36.801215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications import VGG16\nimport numpy as np\n\ndef save_VGG16_outputs(train,\n                       valid):\n    '''\n    將訓練資料、驗證資料輸入VGG16\n    並將兩者的輸出儲存為 npy檔\n\n    parameters:\n    train(DataFrameIterator):預處理完成的訓練資料\n    valid(DataFrameIterator):預處理完成的驗證資料\n    '''\n    # 取得圖像尺寸\n    image_size = len(train[0][0][0])\n    # 將輸入資料的形狀改為Tuple\n    input_shape = (image_size, image_size, 3)\n\n    # 讀入VGG16模型與預學習之參數\n    model = VGG16(include_top=False, # 不用最後3層全連接層\n                  weights='imagenet', # 運用以ImageNet訓練好的參數\n                  input_shape=input_shape) # 輸入資料之形狀\n    #顯示 VGG16概要\n    model.summary()\n\n    # 將訓練資料輸入VGG16模型\n    vgg16_train = model.predict_generator(train, \n                                          steps = len(train),\n                                          verbose=1)\n    \n    # 儲存訓練資料的輸出結果\n    np.save('vgg16_train.npy', vgg16_train)\n\n    # 將驗證資料輸入VGG16模型\n    vgg16_test = model.predict_generator(valid,\n                                         steps = len(valid),\n                                         verbose=1)\n    # 儲存驗證資料的輸出結果\n    np.save('vgg16_test.npy', vgg16_test)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:52:36.804368Z","iopub.execute_input":"2021-06-22T06:52:36.804688Z","iopub.status.idle":"2021-06-22T06:52:36.813337Z","shell.execute_reply.started":"2021-06-22T06:52:36.804657Z","shell.execute_reply":"2021-06-22T06:52:36.812303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom keras.models import Sequential\nfrom keras import optimizers\nfrom keras.layers import Dropout, GlobalMaxPooling2D, Dense\n\ndef train_FClayer(train_labels, validation_labels):\n    '''\n    將VGG16的輸出放入自創的FC層進行學習\n    parameters:\n        train_labels(int的list)   : 訓練資料的正確答案標籤\n        validate_labels(int的list): 驗證資料的正確答案標籤\n    '''\n    # 將VGG16的訓練資料輸出讀入NumPy序列\n    train_data = np.load('vgg16_train.npy')\n    # 將VGG16的驗證資料輸出讀入NumPy序列\n    validation_data = np.load('vgg16_test.npy')\n    \n    # 製作自創的神經網路結構 \n    model = Sequential() \n    # 對四維張量(batch_size, rows, cols, channels)套用池化演算法後\n    # 拉平為二維張量(batch_size, channels) \n    model.add(GlobalMaxPooling2D()) \n    # 全連接層 \n    model.add(Dense(512,                # 神經元數為 512\n                    activation='relu')) # 激活函數為 ReLU\n    # 丟棄率50%\n    model.add(Dropout(0.5))\n\n    # 輸出層\n    model.add(Dense(1,                     # 神經元數為 1\n                    activation='sigmoid')) # 激活函數為Sigmoid\n\n    # 模型編譯\n    model.compile(loss='binary_crossentropy',\n                  optimizer=optimizers.RMSprop(lr=1e-5), # 學習率為預設值的1/100\n                  metrics=['accuracy'])\n\n    # 訓練模型\n    epoch = 20      # 訓練週期\n    batch_size = 16 # 批次大小\n    history = model.fit(train_data,   # 訓練資料\n                        train_labels, # 訓練資料正確答案\n                        epochs=epoch,\n                        batch_size=batch_size,\n                        verbose=1,\n                        # 驗證資料與正確答案\n                        validation_data=(validation_data,\n                                         validation_labels))\n\n    # 傳回history\n    return history\n","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:52:36.815398Z","iopub.execute_input":"2021-06-22T06:52:36.815758Z","iopub.status.idle":"2021-06-22T06:52:36.841251Z","shell.execute_reply.started":"2021-06-22T06:52:36.815726Z","shell.execute_reply":"2021-06-22T06:52:36.839907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, validate_df = prepareData()","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:52:36.842602Z","iopub.execute_input":"2021-06-22T06:52:36.84293Z","iopub.status.idle":"2021-06-22T06:52:57.488312Z","shell.execute_reply.started":"2021-06-22T06:52:36.842898Z","shell.execute_reply":"2021-06-22T06:52:57.487228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, valid = ImageDataGenerate(train_df, validate_df)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:52:57.48984Z","iopub.execute_input":"2021-06-22T06:52:57.49024Z","iopub.status.idle":"2021-06-22T06:52:57.737826Z","shell.execute_reply.started":"2021-06-22T06:52:57.490198Z","shell.execute_reply":"2021-06-22T06:52:57.736613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_VGG16_outputs(train, valid)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:52:57.739397Z","iopub.execute_input":"2021-06-22T06:52:57.739719Z","iopub.status.idle":"2021-06-22T08:47:55.269045Z","shell.execute_reply.started":"2021-06-22T06:52:57.73969Z","shell.execute_reply":"2021-06-22T08:47:55.268149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels = np.array(train_df['category'])\n# 取得驗證資料的正確答案\nvalidation_labels = np.array(validate_df['category'])\n# 執行訓練模型\nhistory = train_FClayer(train_labels,validation_labels)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T08:47:55.271918Z","iopub.execute_input":"2021-06-22T08:47:55.272502Z","iopub.status.idle":"2021-06-22T08:50:06.951835Z","shell.execute_reply.started":"2021-06-22T08:47:55.27245Z","shell.execute_reply":"2021-06-22T08:50:06.950433Z"},"trusted":true},"execution_count":null,"outputs":[]}]}