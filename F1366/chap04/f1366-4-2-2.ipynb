{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#加上 ! 執行 pip指令、安裝Hyperas。\n!pip install hyperas\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-01T08:50:41.46336Z","iopub.execute_input":"2021-06-01T08:50:41.463798Z","iopub.status.idle":"2021-06-01T08:50:50.104802Z","shell.execute_reply.started":"2021-06-01T08:50:41.46371Z","shell.execute_reply":"2021-06-01T08:50:50.103738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from hyperopt import hp\nfrom hyperopt import Trials, tpe\nfrom hyperas import optim\nfrom hyperas.distributions import choice, uniform\nimport numpy as np\n\ndef prepare_data():\n    \"\"\"\n    準備資料\n    \"\"\"\n    # 在此導入外部資料庫。\n    import numpy as np\n    import pandas as pd\n    from sklearn.model_selection import KFold\n    from tensorflow.keras.utils import to_categorical\n    from tensorflow.keras.models import Sequential\n    from tensorflow.keras.layers import Dense, Activation, Dropout\n\n    # 將train.csv讀入pandas的DataFrame。\n    train = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\n    train_x = train.drop(['label'], axis=1)  # 從train取出圖像資料\n    train_y = train['label']               # 從train取出正確答案\n    test_x = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\n\n    # 將train資料分為訓練資料跟驗證資料。\n    kf = KFold(n_splits=4, shuffle=True, random_state=123)\n    tr_idx, va_idx = list(kf.split(train_x))[0]\n    tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n    tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n\n    # 將圖像像素值除以255.0，限制在0 ~ 1.0範圍內，並轉換為numpy.array。\n    tr_x, va_x = np.array(tr_x / 255.0), np.array(va_x / 255.0)\n\n    # 將正確答案轉換為One-hot encoding呈現。\n    tr_y = to_categorical(tr_y, 10)\n    va_y = to_categorical(va_y, 10)\n\n    return tr_x, tr_y, va_x, va_y\n\ndef create_model(tr_x, tr_y):\n    \"\"\"\n    生成模型\n    \"\"\"\n    # 生成Sequential object。\n    model = Sequential()\n\n    # 第1層神經元數量為784。\n    model.add(Dense(784,\n                    input_dim=tr_x.shape[1],\n                    activation={{choice(['tanh', 'relu'])}}\n                   ))\n    # 在0.2 ~ 0.4的範圍內探尋第1層的丟棄率。\n    model.add(Dropout({{quniform(0.2, 0.4, 0.05)}}))\n\n    # 第2層神經元數量為200。\n    model.add(Dense(200,\n                    activation={{choice(['tanh', 'relu'])}}\n                   ))\n    # 在0.2 ~ 0.4的範圍內探尋第2層的丟棄率。\n    model.add(Dropout({{quniform(0.2, 0.4, 0.05)}}))\n\n    # 第3層神經元數量為25。\n    model.add(Dense(25,\n                    activation={{choice(['tanh', 'relu'])}}\n                   ))\n    # 在0.2 ~ 0.4的範圍內探尋第3層的丟棄率。\n    model.add(Dropout({{quniform(0.2, 0.4, 0.05)}}))\n\n    # 配置輸出層。激活函數使用Softmax。\n    model.add(Dense(10, activation=\"softmax\"))\n\n    # 編譯模型。\n    # 優化器定調為RMSprop。\n    model.compile( loss=\"categorical_crossentropy\",\n                  optimizer='rmsprop',\n                  metrics=[\"accuracy\"])\n\n    # 續練次數為20次。\n    epoch = 20\n    # 將小批次的尺寸嘗試設定為100與200。\n    batch_size = {{choice([100, 200])}}\n    result = model.fit( tr_x, tr_y,\n                       epochs=epoch,\n                       batch_size=batch_size,\n                       validation_data=(va_x, va_y),\n                       verbose=0)\n\n    # 簡單地輸出訓練時的結果。\n    validation_acc = np.amax(result.history['val_accuracy'])\n    print('Best validation acc of epoch:', validation_acc)\n\n    # 持續探尋以求得出validation_acc最小值。\n    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n\n# 執行探尋，次數為100。\nbest_run, best_model = optim.minimize(model=create_model,\n                                      data=prepare_data,\n                                      algo=tpe.suggest,\n                                      max_evals=100,\n                                      eval_space=True,\n                                      notebook_name='__notebook_source__',\n                                      trials=Trials())\n","metadata":{"execution":{"iopub.status.busy":"2021-06-01T08:50:50.107019Z","iopub.execute_input":"2021-06-01T08:50:50.107324Z","iopub.status.idle":"2021-06-01T10:29:26.178946Z","shell.execute_reply.started":"2021-06-01T08:50:50.107294Z","shell.execute_reply":"2021-06-01T10:29:26.175478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 輸出準確率最好的模型。\nprint(best_model.summary())\n# 輸出準確率最佳的參數值。\nprint(best_run)\n\n# 使用驗證資料驗證模型。\n_, _, va_x, va_y = prepare_data()\nval_loss, val_acc = best_model.evaluate(va_x, va_y)\nprint(\"val_loss: \", val_loss) # 輸出損失。\nprint(\"val_acc: \", val_acc) # 輸出準確率。\n","metadata":{"execution":{"iopub.status.busy":"2021-06-01T10:29:26.183624Z","iopub.execute_input":"2021-06-01T10:29:26.183988Z","iopub.status.idle":"2021-06-01T10:29:32.744369Z","shell.execute_reply.started":"2021-06-01T10:29:26.18395Z","shell.execute_reply":"2021-06-01T10:29:32.743477Z"},"trusted":true},"execution_count":null,"outputs":[]}]}